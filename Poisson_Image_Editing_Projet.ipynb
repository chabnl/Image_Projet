{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68ece4cc",
   "metadata": {
    "id": "68ece4cc"
   },
   "source": [
    "# Poisson Image Editing\n",
    "**Un projet qui s'appuit sur l'article écrit par Patrick Pérez, Michel Gangnet et Andrew Blake**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a880f8c",
   "metadata": {
    "id": "8a880f8c"
   },
   "source": [
    "**Blondel Charlotte, Cadaux Ema, Mametjanova Aijana, Cros Marion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b553b7",
   "metadata": {
    "id": "21b553b7"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Notre projet s’intéresse à l’édition d’images en passant par les équations de Poisson.\n",
    "\n",
    "L’édition d’une image peut être soit globale (comme l’application de filtre ou le changement de couleur) soit locale. En ce qui concerne notre projet, nous nous focaliserons sur les modifications effectuées localement. Pour cela, nous selectionnerons manuellement les régions auxquelles nous souhaitons appliquer celles-ci. Les masques binaires nous permettront de selectionner les régions en question.\n",
    "\n",
    "Tout au long de ce notebook, nous allons vous présenter différentes techniques d'édition. Elles iront de l’insertion d’une portion d’image à une autre (une sorte de copier-coller, de clonage) au changement de texture ou de couleur local.\n",
    "\n",
    "Le fil rouge de notre projet est l’équation aux dérivées partielles de Poisson avec conditions aux limites de Dirichlet spécifiant le Laplacien d’une fonction inconnue sur le domaine d’intérêt. Cet outil permet des éditions et des clonages sans effet de discontinuité le long de la bordure des régions selectionnées.\n",
    "\n",
    "Nous verrons que l'unicité de cette solution permet d'otenir des algorithmes robustes d'édition.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acde799",
   "metadata": {
    "id": "5acde799"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2609127d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 42
    },
    "id": "2609127d",
    "outputId": "186b4998-2e9c-4860-9c89-0fd769057039",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as scp\n",
    "import pylab as pyl\n",
    "import pywt\n",
    "import pandas as pd\n",
    "import holoviews as hv\n",
    "import param\n",
    "import scipy.sparse as sp\n",
    "import scipy.sparse.linalg\n",
    "import scipy.io\n",
    "import panel as pn\n",
    "import matplotlib.pyplot as plt\n",
    "from panel.pane import LaTeX\n",
    "import os\n",
    "import requests\n",
    "hv.extension('bokeh')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from PIL import Image\n",
    "import time\n",
    "from io import BytesIO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9870c20c",
   "metadata": {},
   "source": [
    "## Insertion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a43a02",
   "metadata": {},
   "source": [
    "L'idée de l'insertion est de copier les gradients spatiaux ∇S de l'image source S dans l'image cible T, et non les valeurs de couleur de S. Pour réaliser un tel mélange, nous cherchons une image u solution de : $min_u \\int_\\Omega || \\nabla u - \\nabla S ||^2 $ sous la contrainte $u_{D\\backslash \\Omega}=T$, ce qui s'écrit :\n",
    "\n",
    "\\begin{equation*}\n",
    "\\min_u \\int_\\Omega ||\\nabla u-\\nabla S||^2+\\iota_{K}(u)\n",
    "\\end{equation*}\n",
    "\n",
    "avec K l'ensemble des images qui coïncident avec la cible à l'extérieur du masque."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e93da1",
   "metadata": {
    "id": "26e93da1"
   },
   "source": [
    "### Chargement des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec40b8",
   "metadata": {
    "id": "f7ec40b8"
   },
   "outputs": [],
   "source": [
    "caselist=['Ours','Soleil','Femme piscine','Homme piscine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577a8e1a",
   "metadata": {
    "id": "577a8e1a"
   },
   "outputs": [],
   "source": [
    "local=1\n",
    "def chargeData(name):\n",
    "    if local:\n",
    "        if name=='Ours':\n",
    "            target=Image.open(\"./data/target_ocean.jpg\")\n",
    "            source=Image.open(\"./data/source_ours.jpg\")\n",
    "            mask=Image.open(\"./data/mask_ours.png\")\n",
    "\n",
    "        if name=='Femme piscine':\n",
    "            target=Image.open(\"./data/target_ocean.jpg\")\n",
    "            source=Image.open(\"./data/source_femme_piscine.jpg\")\n",
    "            mask=Image.open(\"./data/mask_femme_piscine.jpg\")\n",
    "\n",
    "        if name=='Homme piscine':\n",
    "            target=Image.open(\"./data/target_ocean2.jpg\")\n",
    "            source=Image.open(\"./data/source_homme_piscine.jpg\")\n",
    "            mask=Image.open(\"./data/mask_homme_piscine.jpg\")\n",
    "            \n",
    "        if name=='Soleil':\n",
    "            target=Image.open(\"./data/target_sun.jpg\")\n",
    "            source=Image.open(\"./data/source_sun.jpg\")\n",
    "            mask=Image.open(\"./data/mask_sun.jpg\")\n",
    "\n",
    "        source = source.resize(np.shape(target)[:2][::-1])\n",
    "        mask = mask.resize(np.shape(target)[:2][::-1])\n",
    "\n",
    "        target = np.array(target).astype(float)\n",
    "        source = np.array(source).astype(float)\n",
    "        mask = np.array(mask).astype(float)/255\n",
    "        \n",
    "    return target,source,mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba33c8b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "7ba33c8b",
    "outputId": "6c658739-c962-4b6b-de3f-5d823ad8f1de",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target,source,mask2=chargeData('Ours')\n",
    "\n",
    "optionsRGB=dict(width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "optionsGray=dict(cmap='gray',width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "pn.Row(hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.Image((mask2*255).astype('uint8')).opts(**optionsGray))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22307697",
   "metadata": {
    "id": "22307697"
   },
   "source": [
    "### Calcul des gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e49d06",
   "metadata": {},
   "source": [
    "On commence par définir les fonctions de Gradient et de Divergence discrets. Le **gradient discret** d'une image est utilisé pour représenter les changements d'intensité ou de couleur dans une image. La **divergence discrète** d'une image est une opération qui prend en compte les différences entre les intensités des pixels adjacents dans une image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2956f6",
   "metadata": {
    "id": "4b2956f6"
   },
   "outputs": [],
   "source": [
    "def GradientHor(x):\n",
    "    y=x-np.roll(x,1,axis=1)\n",
    "    y[:,0]=0\n",
    "    return y\n",
    "def GradientVer(x):\n",
    "    y=x-np.roll(x,1,axis=0)\n",
    "    y[0,:]=0\n",
    "    return y\n",
    "def DivHor(x):\n",
    "    N=len(x[0])\n",
    "    y=x-np.roll(x,-1,axis=1)\n",
    "    y[:,0]=-x[:,1]\n",
    "    y[:,N-1]=x[:,N-1]\n",
    "    return y\n",
    "def DivVer(x):\n",
    "    N=len(x)\n",
    "    y=x-np.roll(x,-1,axis=0)\n",
    "    y[0,:]=-x[1,:]\n",
    "    y[N-1,:]=x[N-1,:]\n",
    "    return y\n",
    "def Gradient(x):\n",
    "    y=[]\n",
    "    y.append(GradientHor(x))\n",
    "    y.append(GradientVer(x))\n",
    "    return y\n",
    "def Div(y):\n",
    "    x=DivHor(y[0])+DivVer(y[1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e86ca3",
   "metadata": {
    "id": "81e86ca3"
   },
   "source": [
    "### Gradient et projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98f198",
   "metadata": {},
   "source": [
    "On définit une fonction `proj` qui est la projection en fonction du masque de l'image source. Les pixels de l'image source correspondants aux pixels égaux à 1 du masque sont conservés tandis que ceux n'appartenant pas à cette région sont remplacés par les pixels de l'image cible.\n",
    "\n",
    "On définit aussi une fonction calculant le gradient de notre fonctionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6d4788",
   "metadata": {
    "id": "3b6d4788"
   },
   "outputs": [],
   "source": [
    "def Proj(im,ma,iref):\n",
    "    res = im*ma + iref*(1-ma)\n",
    "\n",
    "    return res\n",
    "\n",
    "#Gradient de la fonctionnelle\n",
    "def GradientFonc(x,y):\n",
    "    g = Gradient(x)\n",
    "    r0 = g[0]-y[0]\n",
    "    r1 = g[1] - y[1]\n",
    "    res = DivHor(r0) + DivVer(r1)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1554ed43",
   "metadata": {
    "id": "1554ed43"
   },
   "source": [
    "### Projection Naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b017061",
   "metadata": {
    "id": "7b017061"
   },
   "source": [
    "Dans cette partie, on souhaite fusionner de manière simple deux images. On choisit tout d'abord l'image source, avec l'objet que l'on veut transférer (une personne, un animal etc...), on créé un masque binaire avec en blanc l'objet que l'on veut transférer et en noir le reste. On choisit une image cible sur laquelle l'objet va être fusionné.\n",
    "\n",
    "Tout d'abord, on effectue une projection simple de l'image source sur l'image cible grâce au masque et à la fonction `proj`. On obtient donc une projection simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UEtO5hBbTGDk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "UEtO5hBbTGDk",
    "outputId": "116ed316-f9e3-4c6d-9ab5-5c932e6d8d81"
   },
   "outputs": [],
   "source": [
    "def naive(im,ma,iref):\n",
    "    x  = Proj(im,ma,iref)\n",
    "    return np.clip(x,0,255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusion naïve\n",
    "res_naive  = naive(source[:,:,0],mask2[:,:,0],target[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335865e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optionsRGB = dict(width=400, height=400)\n",
    "\n",
    "bw_target = hv.Image((target[:,:,0]).astype('uint8')).opts(**optionsGray)\n",
    "bw_source = hv.Image(source[:,:,0].astype('uint8')).opts(**optionsGray)\n",
    "proj_bw = hv.Image((res_naive).astype('uint8')).opts(**optionsGray)\n",
    "\n",
    "target_column = pn.Column(\"Cible\", bw_target)\n",
    "source_column = pn.Column(\"Source\", bw_source)\n",
    "proj_column = pn.Column(\"Projection naïve\", proj_bw)\n",
    "\n",
    "pn.Row(target_column, source_column, proj_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f5c3c5",
   "metadata": {
    "id": "f5f5c3c5"
   },
   "source": [
    "Après avoir fait une projection simple, on obtient une image avec une seule couleur. Pour avoir une image en couleur, nous pouvons diviser nos images source et cible en trois canaux et appliquer `proj` sur ces différents canaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b112f",
   "metadata": {
    "id": "098b112f"
   },
   "outputs": [],
   "source": [
    "# Séparation de l'image en 3 canaux\n",
    "\n",
    "target0=target[:,:,0]\n",
    "source0=source[:,:,0]\n",
    "mask20=mask2[:,:,0]\n",
    "\n",
    "target1=target[:,:,1]\n",
    "source1=source[:,:,1]\n",
    "mask21=mask2[:,:,1]\n",
    "\n",
    "target2=target[:,:,2]\n",
    "source2=source[:,:,2]\n",
    "mask22=mask2[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e3cd74",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "id": "d2e3cd74",
    "outputId": "675d059e-27cc-46fe-925f-df6159215ab3"
   },
   "outputs": [],
   "source": [
    "# Fusion\n",
    "projRGB = np.zeros((np.shape(target)))\n",
    "projRGB[:,:,0]= Proj(source0,mask2[:,:,0],target0)\n",
    "projRGB[:,:,1]= Proj(source1,mask2[:,:,0],target1)\n",
    "projRGB[:,:,2]= Proj(source2,mask2[:,:,0],target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc9dd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "optionsRGB = dict(width=400, height=400)\n",
    "\n",
    "rgb_target = hv.RGB((target).astype('uint8')).opts(**optionsRGB)\n",
    "rgb_source = hv.RGB(source.astype('uint8')).opts(**optionsRGB)\n",
    "proj_rgb = hv.RGB((projRGB).astype('uint8')).opts(**optionsRGB)\n",
    "\n",
    "target_column = pn.Column(\"Cible\", rgb_target)\n",
    "source_column = pn.Column(\"Source\", rgb_source)\n",
    "proj_column = pn.Column(\"Projection naïve\", proj_rgb)\n",
    "\n",
    "pn.Row(target_column, source_column, proj_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fef159",
   "metadata": {
    "id": "c7fef159"
   },
   "source": [
    "Nous pouvons voir que l'image source a bien été fusionnée avec l'image source. Cependant, le masque de l'image source ne correspondant par parfaitement aux contours de l'objet que l'on veut fusionner, nous pouvons utiliser d'autres méthodes qui peuvent corriger ce problème."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92395dd",
   "metadata": {
    "id": "a92395dd"
   },
   "source": [
    "### Forward Backward Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff513b7",
   "metadata": {
    "id": "cff513b7"
   },
   "source": [
    "L'utilisation de l'algorithme de Forward Backward de Poisson nous permet d'ajuster l'image source pour qu'elle corresponde mieux à l'image cible tout en conservant les contraintes apportées par le masque.\n",
    "\n",
    "`FBPoissonEditing` ajuste l'image source pour qu'elle se rapproche de l'image cible à chaque itération tout en ayant pour contrainte le masque de l'image source. Pour cela, on calcule une mise à jour de x en utilisant la formule $x-s*\\nabla f(x,y)$. Ensuite, on effectue une projection de cette mise à jour sur l'image cible en utilisant `proj`. Nous pouvons aussi calculer les composantes du gradient afin de visualiser son évolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceba0812",
   "metadata": {
    "id": "ceba0812"
   },
   "outputs": [],
   "source": [
    "def FBPoissonEditing(targ,sour,ma,step,Niter):\n",
    "\n",
    "    f = []\n",
    "    \n",
    "    # Copie de l'image source\n",
    "    x = np.copy(sour)\n",
    "    \n",
    "    # Calcule le gradient de l'image source\n",
    "    y = Gradient(sour)\n",
    "\n",
    "    for i in range(Niter):\n",
    "        \n",
    "        # Calcule valeur temporaire en utilisant le gradient\n",
    "        temp = x - step * GradientFonc(x,y)\n",
    "\n",
    "        # Projete la valeur temporaire sur l'image cible en utilisant le masque\n",
    "        x = Proj(temp,ma,targ)\n",
    "\n",
    "        # Calcule les gradients de l'image modifiée\n",
    "        f1,f2 = Gradient(x - targ)*ma\n",
    "\n",
    "        # Calcule et stocke la norme L2 des gradients\n",
    "        f.append(np.linalg.norm(f1,2) + np.linalg.norm(f2,2))\n",
    "\n",
    "    return np.clip(x,0,255), f[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60190c85",
   "metadata": {
    "id": "60190c85"
   },
   "outputs": [],
   "source": [
    "step=1/4\n",
    "niter=265\n",
    "\n",
    "# Calcul du temps d'exécution\n",
    "start_time_FB = time.time()\n",
    "\n",
    "# FB sur les 3 canaux\n",
    "res_FB0,f0=FBPoissonEditing(target0,source0,mask20,step,niter)\n",
    "res_FB1,f1=FBPoissonEditing(target1,source1,mask21,step,niter)\n",
    "res_FB2,f2=FBPoissonEditing(target2,source2,mask22,step,niter)\n",
    "\n",
    "end_time_FB = time.time()\n",
    "\n",
    "# Calculez la différence pour obtenir le temps d'exécution\n",
    "execution_time_FB = end_time_FB - start_time_FB\n",
    "\n",
    "# Création d'une image couleur à 3 canaux avec les résultats obtenus\n",
    "res_FB=target.copy()\n",
    "res_FB[:,:,0]=res_FB0\n",
    "res_FB[:,:,1]=res_FB1\n",
    "res_FB[:,:,2]=res_FB2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gqu1eZvzYLMn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "gqu1eZvzYLMn",
    "outputId": "6da81fed-0a89-47a3-c0d2-6cd5576fe5ad"
   },
   "outputs": [],
   "source": [
    "optionsRGB = dict(width=400, height=400)\n",
    "\n",
    "proj_rgb = hv.RGB((projRGB).astype('uint8')).opts(**optionsRGB)\n",
    "fb_rgb = hv.RGB(res_FB.astype('uint8')).opts(**optionsRGB)\n",
    "\n",
    "proj_column = pn.Column(\"Projection naïve\", proj_rgb)\n",
    "fb_column = pn.Column(\"Forward Backward\", fb_rgb)\n",
    "\n",
    "pn.Row(proj_column, fb_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0282fe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Temps d\\'exécution :', execution_time_FB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2470f4",
   "metadata": {
    "id": "bd2470f4"
   },
   "source": [
    "L'image obtenue après avoir effectué l'algorithme Forward Backward de Poisson contient moins de défauts. En effet, les bords autour de l'image source sont moins épais, on peut voir que cet algorithme les a mieux fusionnés avec l'image cible. De plus, l'algorithme met environ 50s à tourner pour l'oursCependant, un point faible de cet algorithme est que si les images que l'on veut traiter sont trop grandes, alors l'algorithme devient vite chronophage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qZXh4DY0e6dY",
   "metadata": {
    "id": "qZXh4DY0e6dY"
   },
   "source": [
    "### FISTA Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383d8745",
   "metadata": {
    "id": "383d8745"
   },
   "source": [
    "Au lieu d'utiliser l'algorithme de Forward-Backward, nous pouvons nous servir de FISTA.\n",
    "\n",
    "L'algorithme `FISTAPoissonEditing` d'ajuster itérativement l'image source vers l'image cible tout en respectant les contraintes du masque. À chaque itération, on calcule une mise à jour de x en utilisant la formule $(x+\\frac{n}{\\alpha + n} * e) - s*\\nabla f(x,y)$ avec $e$  la différence entre les itérations successives. Nous pouvons aussi calculer les composantes du gradient afin de visualiser son évolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hQcYyI3Oe5-N",
   "metadata": {
    "id": "hQcYyI3Oe5-N"
   },
   "outputs": [],
   "source": [
    "def FISTAPoissonEditing(targ,sour,ma,step,alpha,Niter):\n",
    "    f = []\n",
    "    \n",
    "    # Copie de l'image source\n",
    "    x = np.copy(sour)\n",
    "    \n",
    "    xp = np.copy(x)\n",
    "    \n",
    "    # Calcule le gradient de l'image source\n",
    "    y = Gradient(sour)\n",
    "\n",
    "    e = 0\n",
    "\n",
    "    for i in range(Niter):\n",
    "\n",
    "        # Met à jour temp avec une composante de la dernière erreur\n",
    "        temp = x + Niter/(alpha+Niter) * e\n",
    "        \n",
    "        # Met à jour x en utilisant la méthode FISTA et la fonction de gradient\n",
    "        x = temp - step * GradientFonc(temp,y)\n",
    "        \n",
    "        # Projet x sur l'image cible en utilisant le masque\n",
    "        x = Proj(x,ma,targ)\n",
    "\n",
    "        # Met à jour e avec la différence entre x actuel et x précédent (xp)\n",
    "        e = x - xp\n",
    "\n",
    "        # Met à jour xp\n",
    "        xp = np.copy(x)\n",
    "\n",
    "        # Calcule les gradients de l'image modifiée\n",
    "        f1,f2 = Gradient(x - targ)*ma\n",
    "\n",
    "        # Calcule et stocker la norme L2 des gradients\n",
    "        f.append(np.linalg.norm(f1,2) + np.linalg.norm(f2,2))\n",
    "\n",
    "\n",
    "    return np.clip(x,0,255),f[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "i8S3uyJcf6EA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "i8S3uyJcf6EA",
    "outputId": "320589c7-4c50-48d7-bb62-1e9a827c078d"
   },
   "outputs": [],
   "source": [
    "step=1/10\n",
    "niter=300\n",
    "\n",
    "# Calcul du temps d'exécution\n",
    "start_time_FISTA = time.time()\n",
    "\n",
    "# FISTA sur les 3 canaux\n",
    "res_FISTA0,f0=FISTAPoissonEditing(target0,source0,mask20,step,3,niter)\n",
    "res_FISTA1,f1=FISTAPoissonEditing(target1,source1,mask21,step,3,niter)\n",
    "res_FISTA2,f2=FISTAPoissonEditing(target2,source2,mask22,step,3,niter)\n",
    "\n",
    "end_time_FISTA = time.time()\n",
    "\n",
    "# Calculez la différence pour obtenir le temps d'exécution\n",
    "execution_time_FISTA = end_time_FISTA - start_time_FISTA\n",
    "\n",
    "# Création d'une image couleur à 3 canaux avec les résultats obtenus\n",
    "res_FISTA=target.copy()\n",
    "res_FISTA[:,:,0]=res_FISTA0\n",
    "res_FISTA[:,:,1]=res_FISTA1\n",
    "res_FISTA[:,:,2]=res_FISTA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231ac4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optionsRGB = dict(width=400, height=400)\n",
    "\n",
    "proj_rgb = hv.RGB((projRGB).astype('uint8')).opts(**optionsRGB)\n",
    "fista_rgb = hv.RGB(res_FISTA.astype('uint8')).opts(**optionsRGB)\n",
    "\n",
    "proj_column = pn.Column(\"Projection naïve\", proj_rgb)\n",
    "fista_column = pn.Column(\"FISTA\", fista_rgb)\n",
    "\n",
    "pn.Row(proj_column, fista_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14b39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Temps d\\'exécution :', execution_time_FISTA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a080f31",
   "metadata": {},
   "source": [
    "L'image obtenue après avoir effectué l'algorithme FISTA de Poisson contient, comme Forward Backward, moins de défauts. Les bords de l'image source sont toujours moins présents et l'algorithme met environ 50s à tourner pour l'ours. Cependant, cet algorithme est aussi chronophage avec de grandes images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gbpR3RVDgXBf",
   "metadata": {
    "id": "gbpR3RVDgXBf"
   },
   "source": [
    "### Forward Backward vs FISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf68a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "optionsRGB = dict(width=400, height=400)\n",
    "\n",
    "fb_rgb = hv.RGB((res_FB).astype('uint8')).opts(**optionsRGB)\n",
    "fista_rgb = hv.RGB(res_FISTA.astype('uint8')).opts(**optionsRGB)\n",
    "\n",
    "fb_column = pn.Column(\"Forward Backward\", fb_rgb)\n",
    "fista_column = pn.Column(\"FISTA\", fista_rgb)\n",
    "\n",
    "pn.Row(fb_column, fista_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e321b09b",
   "metadata": {},
   "source": [
    "L’algorithme FISTA fusionne davantage l’image source sur l’image cible. On voit que les couleurs de l’image cible sont plus présentes par rapport à l’algorithme Forward Backward. Au niveau du temps de calcul, les deux algorithmes ont un temps d’exécution similaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-xssdEAjnHwW",
   "metadata": {
    "id": "-xssdEAjnHwW"
   },
   "source": [
    "## Edition d'image par Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5kPBwEb4mdyR",
   "metadata": {
    "id": "5kPBwEb4mdyR"
   },
   "source": [
    "La résolution de l’équation de Poisson peut être interprétée comme un problème de minimisation, calculant la fonction dont le gradient est le plus proche, en norme **L2**, d’un champ vectoriel prescrit (le champ vectoriel de guidage), sous des conditions aux limites données. Ceci permet d’interpoler les conditions aux limites vers l’intérieur, tout en suivant de près les variations spatiales du champ de guidage.\n",
    "\n",
    "Les deux prochaines méthodes que nous vous présentons sont basées sur la résolution de l'équation de Poisson pour effectuer des modifications locales de couleur/texture à une image, en utilisant un masque préconcu par l'utilisateur.\n",
    "\n",
    "L'équation de Poisson discrète pour une image en couleur avec trois canaux (R : Rouge, V : Vert, B : Bleu) peut être représentée par le système linéaire **Ab = u**, où :\n",
    "\n",
    "\n",
    "  - **A** est la matrice de Poisson construite à partir du masque et des indices des pixels du masque.\n",
    "  - **b** est le vecteur inconnu que nous voulons résoudre, représentant les changements de couleur/texture que nous appliquerons à l'image.\n",
    "  - **u** est le vecteur de gradient de couleur construit à partir de l'image source, du masque et des conditions au limites (bord).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xXSdgZBHiZ0M",
   "metadata": {
    "id": "xXSdgZBHiZ0M"
   },
   "source": [
    "## Local Color Changes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PGbuiCgeoYP4",
   "metadata": {
    "id": "PGbuiCgeoYP4"
   },
   "source": [
    "La fonction `coefficient_matrix(id_mask, mask2id)` construit la matrice de Poisson `A` nécessaire pour résoudre le système d'équations de la méthode de Poisson.\n",
    "\n",
    "Cette dernière est construite en suivant les règles de l'équation de Poisson discrète. Pour chaque pixel **i** appartenant au masque, l'élément diagonal de la ligne correspondante dans `A` est fixé à **4** selon le \"schéma à cinq points\" de la méthode des différences finies (discrétisation au deuxième ordre de l'équation de Poisson), et les éléments correspondants aux voisins dans `A` sont fixés à **-1**. Si le voisin est en dehors du masque, l'élément dans `A` reste nul pour maintenir la condition de Dirichlet.\n",
    "\n",
    "En résumé :\n",
    "\n",
    "- **$A[i, i]$ = 4**\n",
    "\n",
    "- **$A[i, j]$ = -1** pour chaque voisin **j** du pixel **i** dans le masque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4976d430",
   "metadata": {},
   "source": [
    "<img src=\"./notebook_image/poisson_sys.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Q2DWnerXrA-T",
   "metadata": {
    "id": "Q2DWnerXrA-T"
   },
   "source": [
    "D'autre part, la fonction `compute_u_index(source, mask, index, edge_mask)` calcule le gradient d'un pixel donné ainsi que la condition de Dirichlet sur le bord. Elle prend en compte la condition de Dirichlet (la valeur de pixels hors du masque) et les gradients des pixels voisins dans le masque.\n",
    "\n",
    "Mathématiquement, pour chaque canal **k** (rouge, vert, bleu) et pour chaque pixel **i** appartenant au masque, le composant\n",
    "\n",
    "**$u_i^k$** est calculé comme suit :\n",
    "\n",
    " - **$u_i^k$** = condition de Dirichlet pour le pixel **i** + somme des valeurs des pixels voisins appartenant au masque pour le canal **k** - somme des valeurs des pixels voisins qui ne sont pas inclus dans le masque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d1036",
   "metadata": {},
   "source": [
    "<img src=\"./notebook_image/dirichlet.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q5fKL6jTk8LW",
   "metadata": {
    "id": "q5fKL6jTk8LW"
   },
   "outputs": [],
   "source": [
    "def coefficient_matrix(id_mask, mask2id):\n",
    "  '''\n",
    "    Construit la matrice de poisson A\n",
    "  '''\n",
    "\n",
    "  ## Création d'une matrice vide\n",
    "  N = id_mask.shape[0] # Nombre de points appartenant au masque\n",
    "  A = sp.lil_matrix((N, N), dtype=np.float32)\n",
    "\n",
    "  h, w = mask.shape # Taille de l'image\n",
    "\n",
    "  for i in range(N):\n",
    "\n",
    "    A[i, i] = 4 # Tous les éléments diagonaux de la matrice sont égaux à 4\n",
    "\n",
    "    id_h, id_w = id_mask[i]\n",
    "    neighbors = [(id_h, id_w + 1),(id_h, id_w - 1),(id_h + 1, id_w),(id_h - 1, id_w)]\n",
    "\n",
    "    # On itère sur les pixels voisins\n",
    "    for idx_h, idx_w in neighbors:\n",
    "\n",
    "        # Si le pixel appartient au masque, alors on assigne -1 à l'endroit qui lui correspond dans la matrice\n",
    "        if 0 <= idx_h < h and 0 <= idx_w < w and mask2id[idx_h][idx_w]:\n",
    "\n",
    "            j = mask2id[idx_h][idx_w]\n",
    "            A[i, j] = -1\n",
    "\n",
    "  return A\n",
    "\n",
    "def compute_u_index(source, mask, index):\n",
    "  '''\n",
    "  Calcule le gradient d'un pixel donné ainsi que la condition de dirichlet sur le bord\n",
    "  '''\n",
    "  i, j = index\n",
    "\n",
    "  N = 0.0\n",
    "  dircht_ix = 0.0\n",
    "  grad_idx = 0.0\n",
    "\n",
    "  neighbors = [(i, j+1), (i, j-1), (i+1, j), (i-1, j)]\n",
    "\n",
    "  ## On itère sur les voisins du pixel considéré\n",
    "  for idx in range(len(neighbors)) :\n",
    "\n",
    "      i_ngb, j_ngb = neighbors[idx]\n",
    "\n",
    "      # Si le voisin est hors du masque, on rajoute la valeur de son pixel (condition de dirichlet sur le bord)\n",
    "      dircht_ix += float(not(mask[i_ngb, j_ngb])) * source[i_ngb, j_ngb]\n",
    "\n",
    "      N += mask[i_ngb, j_ngb]\n",
    "      grad_idx -= float(mask[i_ngb, j_ngb])*source[i_ngb, j_ngb]\n",
    "  return dircht_ix + N*source[i,j] + grad_idx\n",
    "\n",
    "def color_gradients(src, mask, id_mask, r, g, b):\n",
    "  '''\n",
    "    Construit le vecteur de gradient u\n",
    "  '''\n",
    "  N = id_mask.shape[0] # Nombre de points appartenant au masque\n",
    "\n",
    "  # On créé un tableau par channel de couleur\n",
    "  u_b = np.zeros(N)\n",
    "  u_g = np.zeros(N)\n",
    "  u_r = np.zeros(N)\n",
    "\n",
    "  # Dilatation des contours obtenus\n",
    "  # Plus la taille du kernel est importante, plus les contours seront larges.\n",
    "  kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "\n",
    "  # On calcule le gradient de chacun des pixels appartenant au masque\n",
    "  for index in range(N):\n",
    "\n",
    "    i, j = id_mask[index]\n",
    "    #on multiplie chaque canal de couleur de b par b,g,r afin de modifier en local la couleur de l'image\n",
    "    u_b[index] = compute_u_index(src[:, :, 0], mask, id_mask[index])*b\n",
    "    u_g[index] = compute_u_index(src[:, :, 1], mask, id_mask[index])*g\n",
    "    u_r[index] = compute_u_index(src[:, :, 2], mask, id_mask[index])*r\n",
    "\n",
    "  return u_b, u_g, u_r"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OkjYwMHYwqE9",
   "metadata": {
    "id": "OkjYwMHYwqE9"
   },
   "source": [
    "La fonction `color_gradients(src, mask, id_mask, r, g, b)` construit le vecteur de gradient **b** pour chaque canal de couleur (rouge, vert, bleu) en utilisant la fonction `compute_u_index` pour chaque pixel appartenant au masque. De plus, afin de modifier la couleur, on multiplie chaque canal de couleur par des coefficients spécifiques.\n",
    "Par exemple, pour l'image d'un pissenlit jaune, multiplier le canal rouge par **1.5** augmente l'intensité du rouge, tandis que multiplier les canaux vert et bleu par **0.5** réduit leur intensité. Cela a pour effet global de déplacer la couleur vers le rouge-orange.\n",
    "\n",
    "\n",
    "La fonction `poisson_local_color_change(src, mask)` applique la modification souhaitée au regard des paramètres définis plus haut.\n",
    "\n",
    "Dans un premier temps, on seuille le masque pour obtenir un masque binaire.\n",
    "On récupère ensuite les coordonnées des éléments du masque et les indices correspondants.\n",
    "On construit la matrice **A** et le vecteur afin de résoudre le système d'équations linéaires **Au = b** pour chaque canal de couleur.\n",
    "Enfin, on remplace les valeurs des pixels appartenant au masque dans l'image source par les valeurs obtenus de **u**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nZK8lUGJlI10",
   "metadata": {
    "id": "nZK8lUGJlI10"
   },
   "outputs": [],
   "source": [
    "def poisson_local_color_change(src, mask, r, g, b):\n",
    "    # Seuillage du masque\n",
    "    _, mask_bin = cv2.threshold(mask, 0, 255, cv2.THRESH_OTSU)\n",
    "    mask_bin = mask_bin/255\n",
    "\n",
    "    # id_mask est un tableau contenant les coordonnées (x, y) des éléments appartenant au masque\n",
    "    id_mask = np.argwhere(mask_bin)\n",
    "\n",
    "    # mask2id est un tableau de la même taille que la source.\n",
    "    # Chaque pixel appartenant au masque est égal à la valeur de son index dans id_mask, les autres pixels sont nuls\n",
    "    mask2id = np.zeros(mask.shape, dtype=np.int32)\n",
    "\n",
    "    for index, (i, j) in enumerate(id_mask):\n",
    "        mask2id[i][j] = index\n",
    "\n",
    "    ###\n",
    "\n",
    "    # Remplit la matrice A\n",
    "    print(\"Step 1: Filling coefficient matrix A\")\n",
    "    A = coefficient_matrix(id_mask, mask2id)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Remplit la matrice u\n",
    "    print(\"Step 2: Filling gradient matrix u\")\n",
    "    u_b,u_g,u_r= color_gradients(src, mask_bin, id_mask, r, g, b)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Résout le système pour chaque canal de couleur\n",
    "    print(\"Step 3: Solve Au = b\")\n",
    "    x_b, _ = sp.linalg.cg(A, u_b)\n",
    "    x_g, _ = sp.linalg.cg(A, u_g)\n",
    "    x_r, _ = sp.linalg.cg(A, u_r)\n",
    "    print(\"done!\\n\")\n",
    "\n",
    "    # On remplace dans la source la valeur des pixels appartenant au masque par les valeurs calculées\n",
    "    erased = src.copy()\n",
    "    for index, (i, j) in enumerate(id_mask):\n",
    "\n",
    "        erased[i][j][0] = np.clip(x_b[index], 0.0, 1.0)\n",
    "        erased[i][j][1] = np.clip(x_g[index], 0.0, 1.0)\n",
    "        erased[i][j][2] = np.clip(x_r[index], 0.0, 1.0)\n",
    "\n",
    "    return np.array(erased*255, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zIb6vpMitC1Q",
   "metadata": {
    "id": "zIb6vpMitC1Q"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TSfNBulexfBk",
   "metadata": {
    "id": "TSfNBulexfBk"
   },
   "source": [
    "**Etude de cas 1 : Pissenlit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9656a3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "f9656a3c",
    "outputId": "c5c255ff-5b0f-4d79-8dd9-5e08268617eb"
   },
   "outputs": [],
   "source": [
    "# Importation de la source et du masque\n",
    "src_path = './data/image_pissenlit.jpg'\n",
    "src_mask_path = './data/image_pissenlit_masque.jpg'\n",
    "\n",
    "filename_src, ext_src = os.path.splitext( os.path.basename(src_path) )\n",
    "output_name = './data/' + filename_src + '_processed' + ext_src\n",
    "\n",
    "src = np.array(cv2.imread(src_path, 1)/255.0, dtype=np.float32)\n",
    "mask = np.array(cv2.imread(src_mask_path, 0), dtype=np.uint8)\n",
    "\n",
    "# Réalisation du changement de couleur ~ 5 min\n",
    "erased = poisson_local_color_change(src,mask, 1.5, 0.5, 0.5)\n",
    "\n",
    "# Sauvegarde des résultats dans ./data/\n",
    "merged_result = np.hstack((np.array(src*255, dtype=np.uint8), cv2.merge((mask, mask, mask)), erased))\n",
    "cv2.imwrite(output_name, merged_result)\n",
    "cv2_imshow(merged_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VtA_hhEexl7v",
   "metadata": {
    "id": "VtA_hhEexl7v"
   },
   "source": [
    "**Etude de cas 2 : Poivron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ye8VBnvUxo6Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "Ye8VBnvUxo6Q",
    "outputId": "e4910dd9-789b-4531-9f50-c25d159ec5b5"
   },
   "outputs": [],
   "source": [
    "# Importation de la source et du masque\n",
    "src_path = './data/poivron.png'\n",
    "src_mask_path = './data/masque_poivron_2.png'\n",
    "\n",
    "filename_src, ext_src = os.path.splitext( os.path.basename(src_path) )\n",
    "output_name = './data/' + filename_src + '_processed' + ext_src\n",
    "\n",
    "src = np.array(cv2.imread(src_path, 1)/255.0, dtype=np.float32)\n",
    "mask = np.array(cv2.imread(src_mask_path, 0), dtype=np.uint8)\n",
    "\n",
    "# Réalisation du changement de couleur ~ 11 minutes\n",
    "erased = poisson_local_color_change(src,mask, 2, 0.25, 0.25)\n",
    "\n",
    "# Sauvegarde des résultats dans ./data/\n",
    "merged_result = np.hstack((np.array(src*255, dtype=np.uint8), cv2.merge((mask, mask, mask)), erased))\n",
    "cv2.imwrite(output_name, merged_result)\n",
    "cv2_imshow(merged_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1WLGls788So",
   "metadata": {
    "id": "c1WLGls788So"
   },
   "source": [
    "**Etude de cas 3: Chat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iUKkQ75J8kgf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "id": "iUKkQ75J8kgf",
    "outputId": "26764ec2-e70a-4d0c-f79b-ed7cd0531c80"
   },
   "outputs": [],
   "source": [
    "# Importation de la source et du masque\n",
    "src_path = './data/chat_orange.jpg'\n",
    "src_mask_path = './data/chat_orange_masque.jpg'\n",
    "\n",
    "filename_src, ext_src = os.path.splitext( os.path.basename(src_path) )\n",
    "output_name = './data/' + filename_src + '_processed' + ext_src\n",
    "\n",
    "src = np.array(cv2.imread(src_path, 1)/255.0, dtype=np.float32)\n",
    "mask = np.array(cv2.imread(src_mask_path, 0), dtype=np.uint8)\n",
    "\n",
    "# Réalisation du changement de couleur ~\n",
    "erased = poisson_local_color_change(src,mask, 1.6, 0.8, 0.9)\n",
    "\n",
    "# Sauvegarde des résultats dans ./data/\n",
    "merged_result = np.hstack((np.array(src*255, dtype=np.uint8), cv2.merge((mask, mask, mask)), erased))\n",
    "cv2.imwrite(output_name, merged_result)\n",
    "cv2_imshow(merged_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1030bf8c",
   "metadata": {
    "id": "1030bf8c"
   },
   "source": [
    "## Face fattening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a514027",
   "metadata": {},
   "source": [
    "L'anonymisation des visages est primordiale dans divers contextes pour protéger la vie privée des individus et garantir le respect des règles de confidentialité :\n",
    "\n",
    "- En sciences sociales et en recherche clinique par exemple, de nombreuses études impliquent des participants humains. L'anonymisation des visages garantit que ceux-ci ne soient pas identifiables dans les données collectées. Il est est de même dans le domaine de la médecine pour l'anonymisation des patients.\n",
    "\n",
    "- L'entraînement des algorithmes de reconnaissance faciale est réalisé grâce à des bases de données nécessitant l'anonymisation des individus afin d'assurer le respect de la confidentialité.\n",
    "\n",
    "- Lors de la diffusion d'images provenant de caméras de surveillance publiques, l'anonymisation des visages contribue à protéger la vie privée des citoyens tout en permettant d’assurer la surveillance nécessaire. Une mauvaise utilisation des bases de données peut créer des polémiques comme en 2021 lors de l'utilisation de ClearView AI par la police pour traquer les criminels. Les milliards de visages présents dans la base de données ont soulevé des préoccupations dans la population sur le droit de la police d'utiliser une telle base de données à des fins de surveillance criminelle.\n",
    "\n",
    "- Les médias utilisent également des techniques d'anonymisation des visages afin de protéger l'identité des personnes impliquées dans des reportages ou des documentaires sensibles.\n",
    "\n",
    "\n",
    "Ainsi, l’utilisation de telles bases de données pose de nombreux problèmes éthiques, juridiques et scientifiques. Les risques pour la vie privée sont encore plus importants si l'on considère les conséquences de l’utilisation de ces données à des fins détournées de leur but initial.\n",
    "\n",
    "Pour empêcher l'utilisation abusive des ensembles de données tout en permettant le développement d'applications futures, il est donc primordial que les ensembles de données puissent être anonymisés de manière à préserver l'utilité des données.\n",
    "\n",
    "Les images faciales représentent l'un des types d'informations les plus complexes car les visages fournissent une représentation directe de l'identité des êtres humains. Pour préserver les caractéristiques faciales des données, la possibilité étudiée dans ce Notebook est de préserver les yeux, les lèvres et le nez de l’image originale.\n",
    "\n",
    "La démarche utilisée reprend celle décrite au-dessus pour le changement de couleur local appliqué à une région donnée. Seul le calcul du vecteur de gradient u diffère.\n",
    "\n",
    "Le vecteur **u** est obtenu en additionnant le gradient d’un pixel donné avec la condition de Dirichlet sur le bord du masque. \n",
    "La condition de Dirichlet d’un pixel du masque est obtenue additionnant les valeurs de ses pixels voisins si ceux-ci n'appartiennent pas au masque.\n",
    "\n",
    "<img src=\"./notebook_image/gradient.png\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8514f80",
   "metadata": {
    "id": "d8514f80"
   },
   "outputs": [],
   "source": [
    "def coefficient_matrix(id_mask, mask2id):\n",
    "  '''\n",
    "    Construit la matrice de poisson A\n",
    "  '''\n",
    "\n",
    "  ## Création d'une matrice vide\n",
    "  N = id_mask.shape[0] # Nombre de points appartenant au masque\n",
    "  A = sp.lil_matrix((N, N), dtype=np.float32)\n",
    "\n",
    "  h, w = mask.shape # Taille de l'image\n",
    "\n",
    "  for i in range(N):\n",
    "\n",
    "    A[i, i] = 4 # Tous les éléments diagonaux de la matrice sont égaux à 4\n",
    "\n",
    "    id_h, id_w = id_mask[i]\n",
    "    neighbors = [(id_h, id_w + 1),(id_h, id_w - 1),(id_h + 1, id_w),(id_h - 1, id_w)]\n",
    "\n",
    "    # On itère sur les pixels voisins\n",
    "    for idx_h, idx_w in neighbors:\n",
    "\n",
    "        # Si le pixel appartient au masque, alors on assigne -1 à l'endroit qui lui correspond dans la matrice\n",
    "        if 0 <= idx_h < h and 0 <= idx_w < w and mask2id[idx_h][idx_w]:\n",
    "\n",
    "            j = mask2id[idx_h][idx_w]\n",
    "            A[i, j] = -1\n",
    "\n",
    "  return A\n",
    "\n",
    "def compute_u_ij(source, mask, index, edge_mask):\n",
    "  '''\n",
    "  Calcule le gradient d'un pixel donné ainsi que la condition de dirichlet sur le bord\n",
    "  '''\n",
    "  i, j = index\n",
    "\n",
    "  dircht_ix = 0.0\n",
    "  grad_idx = 0.0\n",
    "\n",
    "  neighbors = [(i, j+1), (i, j-1), (i+1, j), (i-1, j)]\n",
    "  cor_edge = [(i, j), (i, j-1), (i, j), (i-1, j)]\n",
    "\n",
    "  ## On itère sur les voisins du pixel considéré\n",
    "  for idx in range(len(neighbors)) :\n",
    "\n",
    "      i_ngb, j_ngb = neighbors[idx]\n",
    "      i_edg, j_edg = cor_edge[idx]\n",
    "\n",
    "      # Si le voisin est hors du masque, on rajoute la valeur de son pixel (condition de dirichlet sur le bord)\n",
    "      dircht_ix += float(not(mask[i_ngb, j_ngb])) * source[i_ngb, j_ngb]\n",
    "\n",
    "      # Si le voisin appartient au masqu, on calcule son gradient\n",
    "      grad_idx += float(mask[i_ngb, j_ngb]) * (source[i, j]-source[i_ngb, j_ngb]) * edge_mask[i_edg][j_edg]\n",
    "\n",
    "  return dircht_ix + grad_idx\n",
    "\n",
    "def texture_flatten(src, mask, id_mask):\n",
    "  '''\n",
    "    Construit le vecteur de gradient u\n",
    "  '''\n",
    "  N = id_mask.shape[0] # Nombre de points appartenant au masque\n",
    "\n",
    "  # On créé un tableau par channel de couleur\n",
    "  u_b = np.zeros(N)\n",
    "  u_g = np.zeros(N)\n",
    "  u_r = np.zeros(N)\n",
    "\n",
    "  ### Extraction des countours de l'image source (ex. yeux, cheveux,..)\n",
    "  gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "  raw_edge = cv2.Canny(np.array(gray*255, dtype=np.uint8), 100, 200)\n",
    "\n",
    "  # Dilatation des contours obtenus\n",
    "  # Plus la taille du kernel est importante, plus les contours seront larges.\n",
    "  kernel = np.ones((3, 3), dtype=np.uint8)\n",
    "  edge_mask = cv2.dilate(raw_edge, kernel, iterations=1)/255\n",
    "\n",
    "  # On calcule le gradient de chacun des pixels appartenant au masque\n",
    "  for index in range(N):\n",
    "\n",
    "    i, j = id_mask[index]\n",
    "\n",
    "    u_b[index] = compute_u_ij(src[:, :, 0], mask, id_mask[index], edge_mask)\n",
    "    u_g[index] = compute_u_ij(src[:, :, 1], mask, id_mask[index], edge_mask)\n",
    "    u_r[index] = compute_u_ij(src[:, :, 2], mask, id_mask[index], edge_mask)\n",
    "\n",
    "  return edge_mask, u_b, u_g, u_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e102726",
   "metadata": {
    "id": "2e102726",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def poisson_face_flatten(src, mask):\n",
    "    # Seuillage du masque avec la méthode Otsu\n",
    "    _, mask_bin = cv2.threshold(mask, 0, 255, cv2.THRESH_OTSU)\n",
    "    mask_bin = mask_bin/255\n",
    "\n",
    "    # id_mask est un tableau contenant les coordonnées (x, y) des éléments appartenant au masque\n",
    "    id_mask = np.argwhere(mask_bin)\n",
    "\n",
    "    # mask2id est un tableau de la même taille que la source.\n",
    "    # Chaque pixel appartenant au masque est égal à la valeur de son index dans id_mask, les autres pixels sont nuls\n",
    "    mask2id = np.zeros(mask.shape, dtype=np.int32)\n",
    "\n",
    "    for index, (i, j) in enumerate(id_mask):\n",
    "        mask2id[i][j] = index\n",
    "\n",
    "    ###\n",
    "\n",
    "    # Remplit la matrice A\n",
    "    print(\"Step 1: Filling coefficient matrix A\")\n",
    "    A = coefficient_matrix(id_mask, mask2id)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Remplit la matrice u\n",
    "    print(\"Step 2: Filling gradient matrix u\")\n",
    "    edge_mask,u_b,u_g,u_r= texture_flatten(src, mask_bin, id_mask)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Résout le système pour chaque canal de couleur\n",
    "    print(\"Step 3: Solve Au = b\")\n",
    "    x_b, _ = sp.linalg.cg(A, u_b)\n",
    "    x_g, _ = sp.linalg.cg(A, u_g)\n",
    "    x_r, _ = sp.linalg.cg(A, u_r)\n",
    "    print(\"done!\\n\")\n",
    "\n",
    "    # On remplace dans la source la valeur des pixels appartenant au masque par les valeurs calculées\n",
    "    erased = src.copy()\n",
    "    for index, (i, j) in enumerate(id_mask):\n",
    "\n",
    "        erased[i][j][0] = np.clip(x_b[index], 0.0, 1.0)\n",
    "        erased[i][j][1] = np.clip(x_g[index], 0.0, 1.0)\n",
    "        erased[i][j][2] = np.clip(x_r[index], 0.0, 1.0)\n",
    "\n",
    "    return edge_mask,np.array(erased*255, dtype=np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9086f96",
   "metadata": {
    "id": "e9086f96",
    "outputId": "0cc45d40-365b-4a2b-c8ea-3849a9450229",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importation de la source et du masque\n",
    "src_path = './data/source_awkward.png'\n",
    "src_mask_path = './data/mask_awkward.png'\n",
    "\n",
    "filename_src, ext_src = os.path.splitext( os.path.basename(src_path) )\n",
    "output_name = './data/' + filename_src + '_processed' + ext_src\n",
    "\n",
    "src = np.array(cv2.imread(src_path, 1)/255.0, dtype=np.float32)\n",
    "mask = np.array(cv2.imread(src_mask_path, 0), dtype=np.uint8)\n",
    "\n",
    "# Réalisation du floutage, temps de compilation ~ 2 minutes\n",
    "edge_mask,erased = poisson_face_flatten(src,mask)\n",
    "\n",
    "# Sauvegarde des résultats dans ./data/\n",
    "merged_result = np.hstack((np.array(src*255, dtype=np.uint8), cv2.merge((mask, mask, mask)), cv2.merge((edge_mask*255, edge_mask*255, edge_mask*255)), erased))\n",
    "cv2.imwrite(output_name, merged_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2262bf6a",
   "metadata": {},
   "source": [
    "**Tests effectués**\n",
    "\n",
    "<img src=\"./data/source_lesggy_processed.jpg\" width=\"800\"/>\n",
    "<img src=\"./data/source_ajoli_processed.jpg\" width=\"800\"/>\n",
    "<img src=\"./data/source_chalamet_processed.png\" width=\"800\"/>\n",
    "<img src=\"./data/source_awkward_processed.png\" width=\"800\"/>\n",
    "<img src=\"./data/source_killian_processed.jpg\" width=\"800\"/>\n",
    "\n",
    "L'algorithme offre de bonnes performances, il fonctionne même sur des personnes portant des lunettes. Cependant, la barbe, la texture de peau ainsi que les rides perturbent le floutage. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d55d1a",
   "metadata": {},
   "source": [
    "## Mixed seamless cloning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761138e8",
   "metadata": {},
   "source": [
    "### Charging data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "caselist=['Function','Cheese','Donut', 'Rainbow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a73adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def charge_data_MPE(case:str):\n",
    "    if case==caselist[0]:\n",
    "        target=np.array(Image.open(\"./data/function_target.png\")).astype(float)\n",
    "        source=np.array(Image.open(\"./data/function_source.png\")).astype(float)\n",
    "        mask=np.array(Image.open(\"./data/function_mask2.png\")).astype(float)/255\n",
    "        mask=mask[:,:,0]\n",
    "        mask_elab=np.array(Image.open(\"./data/function_mask.png\")).astype(float)/255 #masque élaborée qui répète exactement la forme de l'objet à insérer\n",
    "    elif case==caselist[1]:\n",
    "        target=np.array(Image.open(\"./data/cheese_target.png\")).astype(float)\n",
    "        source=np.array(Image.open(\"./data/cheese_source.png\")).astype(float)\n",
    "        mask=np.array(Image.open(\"./data/cheese_mask.png\")).astype(float)/255\n",
    "        mask=mask[:,:,0]\n",
    "        mask_elab=None\n",
    "    elif case==caselist[2]:\n",
    "        target=np.array(Image.open(\"./data/donut_target.jpeg\")).astype(float)\n",
    "        source=np.array(Image.open(\"./data/donut_source.jpeg\")).astype(float)\n",
    "        mask=np.array(Image.open(\"./data/donut_mask.jpeg\")).astype(float)/255\n",
    "        mask_elab=None\n",
    "    else:\n",
    "        target=np.array(Image.open(\"./data/rainbow_target.png\")).astype(float)\n",
    "        source=np.array(Image.open(\"./data/rainbow_source.png\")).astype(float)\n",
    "        mask=np.array(Image.open(\"./data/rainbow_mask.png\")).astype(float)/255\n",
    "        mask=mask[:,:,0]\n",
    "        mask_elab=None\n",
    "\n",
    "    return target, source,mask,mask_elab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640f3c0",
   "metadata": {},
   "source": [
    "### First case: example from the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fef1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target,source,mask,mask_elab=charge_data_MPE(\"Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5785adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "optionsRGB=dict(width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "optionsGray=dict(cmap='gray',width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "\n",
    "pn.Row(hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(source.astype('uint8')).opts(**optionsRGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2421d055",
   "metadata": {},
   "source": [
    "Afin de réaliser une insertion de l'image source (à gauche) dans l'image target (à droite), nous avons besoin de créer un masque. Nous pouvons créer un masque élaboré qui prend en compte la forme de l'image source avec les trous. Cependant, nous verrons par la suite qu'il existe une technique de Poisson Image Editing appelée mixed seamless cloning qui nous permettra d'éviter ce tracas et d'utiliser un masque très simple, sans sélection élaborée. Nous utiliserons donc par la suite le masque à gauche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cae325",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(hv.Image((mask*255).astype('uint8')).opts(**optionsGray),hv.Image((mask_elab*255).astype('uint8')).opts(**optionsGray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10726ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Proj(im,ma,iref): \n",
    "    tmp=iref*(np.ones(np.shape(ma))-ma)\n",
    "    tmp2=im*ma\n",
    "    res=tmp+tmp2\n",
    "    return res\n",
    "\n",
    "def GradientFonc(x,y):\n",
    "    res=[]\n",
    "    res.append(Gradient(x)[0]-y[0])\n",
    "    res.append(Gradient(x)[1]-y[1])\n",
    "    res1=Div(res)\n",
    "    return res1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca69c8e",
   "metadata": {},
   "source": [
    "Afin d'appliquer la méthode de mixed seamless cloning, nous allons modifier guidance field en appliquant la formule donnée dans l'article :\n",
    "\n",
    "$$\n",
    "v(x)=\n",
    "\\begin{cases}\n",
    "    \\nabla f^*(x) & \\text{si } |\\nabla f^*(x)| > |\\nabla g (x)|, \\\\\n",
    "    \\nabla g(x) & \\text{sinon},\n",
    "\\end{cases}\n",
    "$$\n",
    "ou bien sa version  discrétisée : \n",
    "$$\n",
    "v_{pq} =\n",
    "\\begin{cases}\n",
    "    f_p^* - f_q^* & \\text{si } |f_p^* - f_q^*| > |g_p - g_q|, \\\\\n",
    "    g_p - g_q & \\text{sinon},\n",
    "\\end{cases}\n",
    "$$\n",
    "pour tous les $<p,q>$. \n",
    "\n",
    "On rappelle que $<p,q>$ est un couple de pixels avec $p \\in S $ ($S$ = image source), $q \\in N_p (N_p$ = ensemble des quatre voisins de $p$), $f^*$ est le gradient de l'image cible et $g$ est le gradient de l'image source.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c97a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guidance_field(f, g):\n",
    "    grad_f = Gradient(f)\n",
    "    grad_g = Gradient(g)\n",
    "    grad = []\n",
    "    for i in range(2):\n",
    "        mask  = np.abs(grad_f[i]) > np.abs(grad_g[i])\n",
    "        grad_elem = np.where(mask, grad_f[i], grad_g[i])\n",
    "        grad.append(grad_elem)\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ef3876",
   "metadata": {},
   "source": [
    "Nous séparons les images sources et target par chaque canal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c975423",
   "metadata": {},
   "outputs": [],
   "source": [
    "target0=target[:,:,0]\n",
    "source0=source[:,:,0]\n",
    "target1=target[:,:,1]\n",
    "source1=source[:,:,1]\n",
    "target2=target[:,:,2]\n",
    "source2=source[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bb916",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBMixedPoissonEditing(targ,sour,ma,step,Niter):\n",
    "    x=sour\n",
    "    f=[]\n",
    "    guidance = guidance_field(targ, sour)\n",
    "    for i in range(Niter):\n",
    "        x=Proj(x-step*GradientFonc(x,guidance),ma,targ)\n",
    "        aux=[]\n",
    "        aux.append(Gradient(x)[0]-guidance[0])\n",
    "        aux.append(Gradient(x)[1]-guidance[1])\n",
    "        F_u=1/2*np.linalg.norm(aux)**2\n",
    "        f.append(F_u)\n",
    "    return np.clip(x,0,255),f[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c68e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTAMixedPoissonEditing(targ,sour,ma,step,alpha,Niter):\n",
    "    x=sour.copy()\n",
    "    f=[]\n",
    "    x_old=x.copy()\n",
    "    alpha_old = alpha\n",
    "    guidance = guidance_field(targ, sour)\n",
    "    for i in range(Niter):\n",
    "        alpha_new = (1 + np.sqrt(1 + 4 * alpha_old**2)) / 2\n",
    "        y = x + ((alpha_old - 1) / alpha_new) * (x - x_old)\n",
    "        x_old=x.copy()\n",
    "        x=Proj(y-step*GradientFonc(y,guidance),ma,targ)\n",
    "        aux=[]\n",
    "        aux.append(Gradient(x)[0]-guidance[0])\n",
    "        aux.append(Gradient(x)[1]-guidance[1])\n",
    "        F_u=1/2*np.linalg.norm(aux)**2\n",
    "        f.append(F_u)\n",
    "        alpha_old = alpha_new\n",
    "    return np.clip(x,0,255),f[10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd76384",
   "metadata": {},
   "source": [
    "Nous utilisons ici l'algorithme FISTA telle que codé en TP avec une modification de alpha. Si en TP nous avons utilisé un alpha constant (y était alors égal à $x + \\alpha * (x-x_{old})$), ici cela ne nous donnait pas de résultats satisfaisants. Nous avons donc utilisée une formule de mise à jour de alpha et nous verrons par la suite que nous obtenons des résultats satisfaisants. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Niter=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0_FB,f_FB=FBMixedPoissonEditing(target0,source0,mask,1/8,Niter)\n",
    "res1_FB,f_FB=FBMixedPoissonEditing(target1,source1,mask,1/8,Niter)\n",
    "res2_FB,f_FB=FBMixedPoissonEditing(target2,source2,mask,1/8,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f0249",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res0_FISTA,f_FISTA=FISTAMixedPoissonEditing(target0,source0,mask,1/8,1,Niter)\n",
    "res1_FISTA,f_FISTA=FISTAMixedPoissonEditing(target1,source1,mask,1/8,1,Niter)\n",
    "res2_FISTA,f_FISTA=FISTAMixedPoissonEditing(target2,source2,mask,1/8,1,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c712c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FB, label='Cost function FB', color='blue') \n",
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FISTA, label='Cost function FISTA', color='red')  \n",
    "\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('f')\n",
    "plt.title('Cost function: FB vs FISTA')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816c56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_f=np.zeros((95,104,3))\n",
    "res_f[:,:,0]=res0_FB\n",
    "res_f[:,:,1]=res1_FB\n",
    "res_f[:,:,2]=res2_FB\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eae26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_f=np.zeros((95,104,3))\n",
    "res_f[:,:,0]=res0_FISTA\n",
    "res_f[:,:,1]=res1_FISTA\n",
    "res_f[:,:,2]=res2_FISTA\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d204a707",
   "metadata": {},
   "source": [
    "Nous observons que nous obtenons des résultats satisfaisants pour 1000 itérations avec la téchnique de Mixed Poisson Editing. De plus, nous avons constaté que dans ce cas, un alpha constant dans l'algorithme FISTA ne donnait pas des résultats satisfaisants. Nous avons donc implementé la formule de mise à jour de alpha issue des méthodes de gradient accélérées de Yurii Nesterov.\n",
    "Comparons ces resultats avec les images obtenues en utilisant la téchnique de seamless cloning où l'on l'utilise le gradient de l'image source comme guidance field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c32770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FBPoissonEditing_seamless_cloning(targ,sour,ma,step,Niter):\n",
    "    x=sour\n",
    "    f=[]\n",
    "    for i in range(Niter):\n",
    "        x=Proj(x-step*GradientFonc(x,Gradient(sour)),ma,targ)\n",
    "        aux=[]\n",
    "        aux.append(Gradient(x)[0]-Gradient(sour)[0])\n",
    "        aux.append(Gradient(x)[1]-Gradient(sour)[1])\n",
    "        F_u=1/2*np.linalg.norm(aux)**2\n",
    "        f.append(F_u)\n",
    "        #f=GradientFonc\n",
    "    return np.clip(x,0,255),f[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0_SC,f_SC=FBPoissonEditing_seamless_cloning(target0,source0,mask,1/8,Niter)\n",
    "res1_SC,f_SC=FBPoissonEditing_seamless_cloning(target1,source1,mask,1/8,Niter)\n",
    "res2_SC,f_SC=FBPoissonEditing_seamless_cloning(target2,source2,mask,1/8,Niter)\n",
    "res_f=np.zeros((95,104,3))\n",
    "res_f[:,:,0]=res0_SC\n",
    "res_f[:,:,1]=res1_SC\n",
    "res_f[:,:,2]=res2_SC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c12889b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b77d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FISTAPoissonEditing_seamless_cloning(targ,sour,ma,step,alpha,Niter):\n",
    "    x=sour\n",
    "    f=[]\n",
    "    x_old=x.copy()\n",
    "    alpha_old=alpha\n",
    "    for i in range(Niter):\n",
    "        alpha_new = (1 + np.sqrt(1 + 4 * alpha_old**2)) / 2\n",
    "        y = x + ((alpha_old - 1) / alpha_new) * (x - x_old)\n",
    "        x_old=x.copy()\n",
    "        x=Proj(y-step*GradientFonc(y,Gradient(sour)),ma,targ)\n",
    "        \n",
    "        aux=[]\n",
    "        aux.append(Gradient(x)[0]-Gradient(sour)[0])\n",
    "        aux.append(Gradient(x)[1]-Gradient(sour)[1])\n",
    "        F_u=1/2*np.linalg.norm(aux)**2\n",
    "        f.append(F_u)\n",
    "        alpha_old=alpha_new\n",
    "    return np.clip(x,0,255),f[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d51339",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0_FISTA,f_FISTA=FISTAPoissonEditing_seamless_cloning(target0,source0,mask,1/8,1,Niter)\n",
    "res1_FISTA,f_FISTA=FISTAPoissonEditing_seamless_cloning(target1,source1,mask,1/8,1,Niter)\n",
    "res2_FISTA,f_FISTA=FISTAPoissonEditing_seamless_cloning(target2,source2,mask,1/8,1,Niter)\n",
    "res_f=np.zeros((95,104,3))\n",
    "res_f[:,:,0]=res0_FISTA\n",
    "res_f[:,:,1]=res1_FISTA\n",
    "res_f[:,:,2]=res2_FISTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6faccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a99fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(10,Niter,Niter-10), f_SC, label='Cost function FB', color='blue') \n",
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FISTA, label='Cost function FISTA', color='red')  \n",
    "\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('f')\n",
    "plt.title('Cost function: FB vs FISTA')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e0230",
   "metadata": {},
   "source": [
    "Nous observons que nous obtenons des résultats beaucoup moins satisfaisants avec la téchnique de seamless cloning. En effet, cette téchnique ne prend pas en compte la forme spécifique de l'image source, notamment les trous. \n",
    "\n",
    "Nous constatons alors qu'avec une simple modification de guidance field, Mixed Poisson Editing permet d'obtenir de bons resultats. Il est alors crucial d'adapter le guidance field au problème de Image Editing donné. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f46443a",
   "metadata": {},
   "source": [
    "### Second case: cheddar cheese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822646ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "target,source,mask,mask_elab=charge_data_MPE(\"Cheese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bbbd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "target0=target[:,:,0]\n",
    "source0=source[:,:,0]\n",
    "target1=target[:,:,1]\n",
    "source1=source[:,:,1]\n",
    "target2=target[:,:,2]\n",
    "source2=source[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878bb3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optionsRGB=dict(width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "optionsGray=dict(cmap='gray',width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "\n",
    "pn.Row(hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.Image((mask*255).astype('uint8')).opts(**optionsGray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e190a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Niter=1000\n",
    "res0_FB,f_FB=FBMixedPoissonEditing(target0,source0,mask,1/8,Niter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1_FB,f_FB=FBMixedPoissonEditing(target1,source1,mask,1/8,Niter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb0619",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2_FB,f_FB=FBMixedPoissonEditing(target2,source2,mask,1/8,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fadd262",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c=np.shape(target)\n",
    "res_f=np.zeros((h,w,c))\n",
    "res_f[:,:,0]=res0_FB\n",
    "res_f[:,:,1]=res1_FB\n",
    "res_f[:,:,2]=res2_FB\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0389cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0_FISTA,f_FISTA=FISTAMixedPoissonEditing(target0,source0,mask,1/8,1,Niter)\n",
    "res1_FISTA,f_FISTA=FISTAMixedPoissonEditing(target1,source1,mask,1/8,1,Niter)\n",
    "res2_FISTA,f_FISTA=FISTAMixedPoissonEditing(target2,source2,mask,1/8,1,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184e9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c=np.shape(target)\n",
    "res_f=np.zeros((h,w,c))\n",
    "res_f[:,:,0]=res0_FISTA\n",
    "res_f[:,:,1]=res1_FISTA\n",
    "res_f[:,:,2]=res2_FISTA\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92472a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FB, label='Cost function FB', color='blue') \n",
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FISTA, label='Cost function FISTA', color='red')  \n",
    "\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('f')\n",
    "plt.title('Cost function: FB vs FISTA')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb422a07",
   "metadata": {},
   "source": [
    "### Third case: donut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d5a1d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target,source,mask,mask_elab=charge_data_MPE(\"Donut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target0=target[:,:,0]\n",
    "source0=source[:,:,0]\n",
    "target1=target[:,:,1]\n",
    "source1=source[:,:,1]\n",
    "target2=target[:,:,2]\n",
    "source2=source[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ae3b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "optionsRGB=dict(width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "optionsGray=dict(cmap='gray',width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "\n",
    "pn.Row(hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.Image((mask*255).astype('uint8')).opts(**optionsGray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f72ab2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Niter=1000\n",
    "res0_FB,f_FB=FBMixedPoissonEditing(target0,source0,mask,1/8,Niter)\n",
    "res1_FB,f_FB=FBMixedPoissonEditing(target1,source1,mask,1/8,Niter)\n",
    "res2_FB,f_FB=FBMixedPoissonEditing(target2,source2,mask,1/8,Niter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a7df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c=np.shape(target)\n",
    "res_f=np.zeros((h,w,c))\n",
    "res_f[:,:,0]=res0_FB\n",
    "res_f[:,:,1]=res1_FB\n",
    "res_f[:,:,2]=res2_FB\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0_FISTA,f_FISTA=FISTAMixedPoissonEditing(target0,source0,mask,1/8,1,Niter)\n",
    "res1_FISTA,f_FISTA=FISTAMixedPoissonEditing(target1,source1,mask,1/8,1,Niter)\n",
    "res2_FISTA,f_FISTA=FISTAMixedPoissonEditing(target2,source2,mask,1/8,1,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6dd03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c=np.shape(target)\n",
    "res_f=np.zeros((h,w,c))\n",
    "res_f[:,:,0]=res0_FISTA\n",
    "res_f[:,:,1]=res1_FISTA\n",
    "res_f[:,:,2]=res2_FISTA\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2294633b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FB, label='Cost function FB', color='blue') \n",
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FISTA, label='Cost function FISTA', color='red')  \n",
    "\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('f')\n",
    "plt.title('Cost function: FB vs FISTA')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b9c299",
   "metadata": {},
   "source": [
    "On observe que l'on obtient des résultats beaucoup moins satisfaisants dans les deux derniers cas, même avec le nombre d'itérations important. Afin d'améliorer ces résultats, nous pourrions modifier les paramètres de step et alpha ainsi que d'implémenter des masques un peu plus élaborés que ceux utilisés. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a15a6a",
   "metadata": {},
   "source": [
    "### Fourth case: rainbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b3e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "target,source,mask,mask_elab=charge_data_MPE(\"Rainbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790b5962",
   "metadata": {},
   "outputs": [],
   "source": [
    "target0=target[:,:,0]\n",
    "source0=source[:,:,0]\n",
    "target1=target[:,:,1]\n",
    "source1=source[:,:,1]\n",
    "target2=target[:,:,2]\n",
    "source2=source[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de0b0a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optionsRGB=dict(width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "optionsGray=dict(cmap='gray',width=300,height=300,xaxis=None,yaxis=None,toolbar=None)\n",
    "\n",
    "pn.Row(hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.Image((mask*255).astype('uint8')).opts(**optionsGray))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c89dec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Niter=1000\n",
    "res0_FB,f_FB=FBMixedPoissonEditing(target0,source0,mask,1/8,Niter)\n",
    "res1_FB,f_FB=FBMixedPoissonEditing(target1,source1,mask,1/8,Niter)\n",
    "res2_FB,f_FB=FBMixedPoissonEditing(target2,source2,mask,1/8,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f92ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c=np.shape(target)\n",
    "res_f=np.zeros((h,w,3))\n",
    "res_f[:,:,0]=res0_FB\n",
    "res_f[:,:,1]=res1_FB\n",
    "res_f[:,:,2]=res2_FB\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "res0_FISTA,f_FISTA=FISTAMixedPoissonEditing(target0,source0,mask,1/8,1,Niter)\n",
    "res1_FISTA,f_FISTA=FISTAMixedPoissonEditing(target1,source1,mask,1/8,1,Niter)\n",
    "res2_FISTA,f_FISTA=FISTAMixedPoissonEditing(target2,source2,mask,1/8,1,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd03386",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,w,c=np.shape(target)\n",
    "res_f=np.zeros((h,w,3))\n",
    "res_f[:,:,0]=res0_FISTA\n",
    "res_f[:,:,1]=res1_FISTA\n",
    "res_f[:,:,2]=res2_FISTA\n",
    "pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe05915",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FB, label='Cost function FB', color='blue') \n",
    "plt.plot(np.linspace(10,Niter,Niter-10), f_FISTA, label='Cost function FISTA', color='red')  \n",
    "\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('f')\n",
    "plt.title('Cost function: FB vs FISTA')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205887e5",
   "metadata": {},
   "source": [
    "### Custom modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96ee09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FISTAFusion(param.Parameterized):\n",
    "    case = param.ObjectSelector(default='Function',objects=caselist)\n",
    "    Niter = param.Integer(100,bounds=(10,3000))\n",
    "    step = param.Number(1/8,bounds=(0.1,4))\n",
    "    alpha = param.Number(0.5,bounds=(0.1,5))\n",
    "    def view(self):\n",
    "        target,source,ma,ma_elab=charge_data_MPE(self.case)\n",
    "        target0=target[:,:,0]\n",
    "        source0=source[:,:,0]\n",
    "        target1=target[:,:,1]\n",
    "        source1=source[:,:,1]\n",
    "        target2=target[:,:,2]\n",
    "        source2=source[:,:,2]\n",
    "        res0,F0=FISTAMixedPoissonEditing(target0,source0,ma,self.step,self.alpha,self.Niter)\n",
    "        res1,F1=FISTAMixedPoissonEditing(target1,source1,ma,self.step,self.alpha,self.Niter)\n",
    "        res2,F2=FISTAMixedPoissonEditing(target2,source2,ma,self.step,self.alpha,self.Niter)\n",
    "        h,w=np.shape(target)[0],np.shape(target)[1]\n",
    "        res_f=np.zeros((h,w,3))\n",
    "        res_f[:,:,0]=res0\n",
    "        res_f[:,:,1]=res1\n",
    "        res_f[:,:,2]=res2\n",
    "        F=[sum(f)/3 for f in zip(F0, F1, F2)]\n",
    "        F=plt.plot(F)\n",
    "        return pn.Row(hv.RGB(source.astype('uint8')).opts(**optionsRGB),hv.RGB(target.astype('uint8')).opts(**optionsRGB),hv.RGB(res_f.astype('uint8')).opts(**optionsRGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc78127",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fistafusion=FISTAFusion()\n",
    "pn.Row(fistafusion.param,fistafusion.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a415be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c26598",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
